{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>Brazilian traffic sign recognition: an neural network approach</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Besides autonomous cars technology is actually a trending subject in researches, many subfuctions of a car's embedded system has already been developed and it's currently working in nowadays cars (maybe not in popular ones). Traffic signs recognition (TSR) is one of those already done functions and it has a good performance, but as a driver assistant not as a controller product. Additionally, the recognition system is usually created based in the manufacture country regulations and features. As basically all cars sold in Brazil has imported technology, it's recognition function is disconnected from the system as it has no use there.\n",
    "\n",
    "This paper propose the creation of a dataset based in Brazil's traffic signs regulation, as well a artificial intelligence (AI) application based in training a neural network to classify it. The AI was implemented in TensorFlow framework for Python 3.7.\n",
    "\n",
    "\n",
    "![Examples of brazilian's Traffic signs](http://www.betuseal.com.br/wp-content/uploads/2015/01/placas-transito-sinaliza%C3%A7%C3%A3o-675x414.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Libraries used:\n",
    "\n",
    "- Matplotlib: Python 2D plotting library;\n",
    "- NumPY: Python math package to work with arrays, vectors and matrices;\n",
    "- OS: File and Directory Access;\n",
    "- OpenCV: Image data processing;\n",
    "- Sklearn: Data mining and data analysis;\n",
    "- Skimage: Image data processing;\n",
    "- TensorFlow: Machine Learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import warp\n",
    "from skimage.transform import ProjectiveTransform\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from random import choice\n",
    "from random import randint\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the dataset\n",
    "\n",
    "Examples of Brazilian traffic signs can be individually gathered in [Detran/SE](http://www.detran.se.gov.br/educ_sinal.asp) web site, although it is a manual task, it wouldn't take so long to finish.\n",
    "\n",
    "<table><tr><td><img width=100 src='traffic_signs_classes/0.png'></td><td><img width=100 src='traffic_signs_classes/6.png'></td><td><img width=100 src='traffic_signs_classes/12.png'></td><td><img width=100 src='traffic_signs_classes/13.png'></td></tr></table>\n",
    "\n",
    "As traffic sign has a default shape, it allows removing any unnecessary part and retaining only the important details, reducing the number of data and so, optimizing for data processing.\n",
    "\n",
    "\n",
    "There are differents borders and shapes of signs, as illustrated above, which indicates it's objective (warning, regulation and directions) but it doens't offer any precious information about the sign meaning, so as the colors used. Such statement allow us to reduce data number  without losing any important feature for recognition by previously removing the sign background and convert it to gray scale.\n",
    "\n",
    "Due to remove the signs background, It was manually created a image for each sign in directory \"thresholding\", which contain only the background in the shape of the corresponding sign, also this image has the same name as the original sign for implementation facilities. The examples of thresholding images for the shown signs are demonstrated below.\n",
    "\n",
    "<table><tr><td><img width=100 src='traffic_signs_classes/thresholding/0.jpg'></td><td><img width=100 src='traffic_signs_classes/thresholding/6.jpg'></td><td><img width=100 src='traffic_signs_classes/thresholding/12.jpg'></td><td><img width=100 src='traffic_signs_classes/thresholding/13.jpg'></td></tr></table>\n",
    "\n",
    "Thinking in a real world application, the sign wouldn't be in perfect state and possibly in a different perspective as it should be, so it would be necessary to create those conditions to relate this possibilities to a label. From the 30 signs gathered in the previous database, a total of 500 synthesized versions for each sign were created. Each one of these versions proposes random geometry distortions, brightness, contrast, blur and noises effects, and at least, it is saved as a 56x56 gray pixels gray scale image, as its ilustraded below.\n",
    "\n",
    "<table><tr><td><img width=100 src='Generated/0/0_1.png'></td><td><img width=100 src='Generated/6/6_7.png'></td><td><img width=100 src='Generated/12/12_13.png'></td><td><img width=100 src='Generated/13/13_14.png'></td></tr></table>\n",
    "\n",
    "After all the image processing, our Brazilian traffic sign image dataset is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully created!\n"
     ]
    }
   ],
   "source": [
    "def pespective(input, mascara):\n",
    "    cols = input.shape[1]\n",
    "    rows = input.shape[0]\n",
    "    inputQuad = np.array([[0, 0],[cols, 0],[cols,rows],[0,rows]], np.float32)\n",
    "    outputQuad = np.array([[-randint(0,17),-randint(0,17)],[cols+randint(0,17),-randint(0,17)],\t\n",
    "\t[cols+randint(0,17), rows+randint(0,17)],[-randint(0,17),rows+randint(0,17)]], np.float32)\n",
    "    M = cv2.getPerspectiveTransform(outputQuad, inputQuad)\n",
    "    output = cv2.warpPerspective(input,M,(cols,rows)) \n",
    "    output2 = cv2.warpPerspective(mascara,M,(cols,rows)) \n",
    "    return [output,output2]\n",
    "\n",
    "\n",
    "'''\n",
    "Apply 2D rotation and perspective transformation\n",
    "'''\n",
    "\n",
    "def transformation(name, name2):\n",
    "    src1 = cv2.imread(name, 0)\n",
    "    mask = cv2.imread(name2, 0)\n",
    "    \n",
    "    '''\n",
    "    noise application\n",
    "    '''\n",
    "    \n",
    "    rows, cols = src1.shape\n",
    "    k = 0\n",
    "    for i in range(0, rows):\n",
    "        for j in range(0, cols):\n",
    "            editValue = src1[i, j]\n",
    "            var = randint(25, 100)\n",
    "            k = var\n",
    "            if editValue > 60 and editValue < 160:\n",
    "                src1[i, j] = var\n",
    "            elif editValue > 230 and editValue < 256:\n",
    "                src1[i, j] = 255 - var\n",
    "    if k > 40:\n",
    "        getElement = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        src1 = cv2.erode(src1, getElement)\n",
    "\n",
    "        getElement = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        src1 = cv2.dilate(src1, getElement)\n",
    "\n",
    "    '''\n",
    "    rotation transformation (-20 ate 20 graus)\n",
    "    '''\n",
    "    \n",
    "    image_center = tuple(np.array(src1.shape) / 2)\n",
    "    angle = randint(-30, 30)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(src1, rot_mat, src1.shape, flags=cv2.INTER_LINEAR)\n",
    "    result2 = cv2.warpAffine(mask, rot_mat, mask.shape, flags=cv2.INTER_LINEAR)     \n",
    "\n",
    "\n",
    "    '''\n",
    "    perspective transformation\n",
    "    '''\n",
    "    \n",
    "    img = result\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    pts1 = np.float32([[0, 0], [0, 200], [200, 0], [200, 200]])\n",
    "    seed = randint(0, 1)\n",
    "    variation1 = randint(0, 8)\n",
    "    variation2 = randint(15, 25)\n",
    "\n",
    "    # right direction perspective\n",
    "    if seed == 0:\n",
    "        pts2 = np.float32([[(0 + variation1), 0], [(0 + variation1),\n",
    "                                                   200], [(200 - variation2), 0], [(200 - variation2), 200]])\n",
    "    # left direction perspective\n",
    "    else:\n",
    "        pts2 = np.float32([[(0 + variation2), 0], [(0 + variation2),\n",
    "                                                   200], [(200 - variation1), 0], [(200 - variation1), 200]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    dst = cv2.warpPerspective(img, M, (200, 200))\n",
    "    dst2 = cv2.warpPerspective(result2, M, (200, 200))\n",
    "    \n",
    "    return [dst, dst2]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Save resized image after applying random brightness, constrast and blur effect\n",
    "'''\n",
    "\n",
    "def variation(image,mascara, pasta, arquivo, transf):\n",
    "    \n",
    "    # alpha random values (simple contrast control) (0.4 - 0.9)\n",
    "    alpha = uniform(.4, .9)\n",
    "\n",
    "    # beta random values (simple brightness control) (10 - 20)\n",
    "    beta = randint(12, 16)\n",
    "    \n",
    "    cv2.convertScaleAbs(image, image, alpha, beta)\n",
    "\n",
    "    # add gaussian blurring\n",
    "    size = int(choice('35'))\n",
    "    blur = cv2.GaussianBlur(image, (size, size), 0, 0)\n",
    "    uhu =  cv2.medianBlur(blur,5)    \n",
    "    th, mask_th = cv2.threshold(mascara, 50, 255, cv2.THRESH_BINARY);\n",
    "    blur = cv2.bitwise_and(uhu, mask_th)\n",
    "    final = cv2.resize(blur, (56, 56))\n",
    "  \n",
    "    dirname = \"Generated/\" + str(pasta)+ \"/\"\n",
    "    \n",
    "    if not os.path.exists(dirname):\n",
    "        os.mkdir(dirname)\n",
    "    \n",
    "    cv2.imwrite(dirname + str(arquivo) + \"_\" +str(transf) + \".png\", final)\n",
    "\n",
    "    \n",
    "'''\n",
    "Import each image and pass it data as arguments to the image processing functions\n",
    "In the end of it's execution, all the synthesized images will be saved in \"Generated\" directory\n",
    "'''\n",
    "\n",
    "def create_database():\n",
    "    flag_name = 0\n",
    "    for i in range(0, 30):\n",
    "        filepath = './traffic_signs_classes/' + str(i) + '.png'\n",
    "        filepath2 = './traffic_signs_classes/thresholding/' + str(i) + '.jpg'\n",
    "        for j in range(0, 25):\n",
    "            src, mask = transformation(filepath, filepath2)\n",
    "            for transf in range(0, 20):\n",
    "                src2, mask2 = pespective(src, mask)\n",
    "                variation(src2, mask, i, j, transf)\n",
    "                #print('Class: ' + str(i) + ' Image : ' + str(j) + ' Transformation : ' + str(transf))\n",
    "    print('Dataset successfully created!')\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "create_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a diversified traffic sign samples were created, it's ready to be loaded and pre-processed before initialize the neural network.\n",
    "\n",
    "As usual for image classification, it's matrix element becomes an feature for classification, so a 56 x 56 x 1 (length, width, channel) image is converted to a 56x56x1 = 3136 elements array. Each dataset matrix row correspond to a single sign image loaded, therefore our dataset matrix size is 15000 rows and 3136 columns. \n",
    "\n",
    "As for the label matrix, which relate the feature row to it's traffic sign, the concept of one hot encoding is used. Then, a total of 30 columns are needed for this classification, which each column represents one of the signs examples included in dataset. The number of rows is equal for both feature and label matrix.\n",
    "\n",
    "For the importing algorithm, it will enter each directory where was generated the different samples of each sign, load it's image data in gray scale and append it in the pre-initialized matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_filepath = os.getcwd() + '/Generated//'\n",
    "n_signs = 30\n",
    "y_matrix = np.empty([0, n_signs])\n",
    "x_matrix = []\n",
    "for sign_count in range(0,n_signs):\n",
    "        inputdir =  generated_filepath + str(sign_count) + '//'\n",
    "        y_sign = np.zeros((1,n_signs), dtype=np.int)\n",
    "        y_sign[0][sign_count] = 1\n",
    "        for image in os.listdir(inputdir):\n",
    "            imageFilepath = inputdir + image\n",
    "            img_matrix = cv2.imread(imageFilepath,0)\n",
    "            img_array = np.ravel(img_matrix)\n",
    "            y_matrix = np.concatenate((y_matrix, y_sign), axis=0)\n",
    "            x_matrix.append(img_array)\n",
    "x_matrix = np.array(x_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Network\n",
    "\n",
    "In AI subject, neural network concept was chosen for it's proven efficiency with image classification. As a first approach, it was chosen to use a multi-layer perceptron (MLP) network.\n",
    "\n",
    "### 3.1 Multi-Layer Perceptron\n",
    "\n",
    "Perceptron is an algorithm that maps a function by binary classification. A single layer perceptron example is shown below.\n",
    "\n",
    "![Perceptron function](images/perceptron.png)\n",
    "\n",
    "A simplified perceptron algorithm follow these steps:\n",
    "\n",
    "1. Initialize the weights with random values;\n",
    "2. Select an input vector and present it to the network;\n",
    "3. Compute the output y', the input vectors ($x_i$) and the weights values ($\\omega_i$);\n",
    "4. Apply binary function:\n",
    "\n",
    "$$f(x) =\\begin{cases}\n",
    "               1\\hspace{1mm}if\\hspace{1mm}\\omega\\hspace{1mm}\\times\\hspace{1mm}x\\hspace{1mm}+\\hspace{1mm}b\\hspace{1mm}>\\hspace{1mm}0\\\\\n",
    "               0\\hspace{1mm}if\\hspace{1mm}otherwise\n",
    "            \\end{cases}$$\n",
    "\n",
    "5. If y' $\\neq$ y modify all connections $\\omega_i$ by adding the changes $\\bigtriangleup\\omega = yx_i$;\n",
    "6. Return to step 2.\n",
    "\n",
    "The single layer perceptron can be generalized to many layers connected to each other, as illustrated below.\n",
    "\n",
    "![Multi Layer Perceptron](images/mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Implementation\n",
    "\n",
    "The MLP network is implemented though TensorFlow framework, which includes several functions for Machine Learning. In addition, the environment has Intel Distribution for Python package to enhance the application performance\n",
    "\n",
    "#### 3.2.1 Model Specification\n",
    "\n",
    "Before instantiate the hidden layers, it's necessary to do three things:\n",
    "\n",
    "1. Define the input and output of the data;\n",
    "2. Choose number of hidden layers and number of it's inputs;\n",
    "3. Create the variables corresponding to each weights and bias needed for this neural network.\n",
    "\n",
    "Through Tensorflow method tf.placeholder, input and output is instantiate in the data type and length specified in it's arguments.\n",
    "\n",
    "For a first attempt, it was chosen to use 2 hidden layers with 300 inputs each, so it needs 3 vectors for each variable (weight and bias), as it includes output layer as well. As the parameters are specified, it should initialize it with help of tf.Variable and a value in it's argument. This value can be zero, one or random.\n",
    "\n",
    "Now that all the variables are defined, a layer is created associating those parameters with tf.add and tf.matmul. After it's building, a activation function (in this case, relu or softmax) is associated to each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = np.shape(x_matrix)[1]\n",
    "y_output = np.shape(y_matrix)[1]\n",
    "x = tf.placeholder(tf.float32,[None,n_input])\n",
    "y = tf.placeholder(tf.float32,[None,y_output])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "w2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "b1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "b2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "b_out = tf.Variable(tf.random_normal([y_output]))\n",
    "w_out = tf.Variable(tf.random_normal([n_hidden_2, y_output]))\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(x, w1), b1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "layer_2 = tf.add(tf.matmul(layer_1, w2), b2)\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "out_layer = tf.add(tf.matmul(layer_2,w_out),b_out)\n",
    "pred = tf.nn.softmax(out_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the layers are already done, only the optimizer and cost functions are still missing. Cost will be defined by Cross-Entropy method, which calculate the difference value between the actual and the expected output with help of tf.reduce_mean Tensorflow method.\n",
    " \n",
    "For optimizer, Adam gradient descent function was selected as it performs smooth updates in calculating a new weight and bias in function of the cost retrieved for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_layer,labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model definition is completed and it's ready for training, but it lacks a measure to demonstrate effectiveness. So, as a matter of accuracy calculation between epochs and display it for user visualization, every epoch will run and store the result of an algorithm that compares the maximum classification from output vector and the desired output for the sample injected in the network. If both are equal, it represents a right classification from the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(tf.argmax(out_layer,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Pre-processing data\n",
    "\n",
    "Before splitting the dataset matrix in a training set and validation set for cross-validation method application, it's applied a feature scaling so it's values becomes between 0~1, to offer at least a faster convergence in training phase. It's done with help from sklearn preprocessing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_matrix_scale = min_max_scaler.fit_transform(x_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Execution of training\n",
    "\n",
    "The dataset is separated in the session's beginning in to test set and validation set, as it will be used for cross-validation method. The test set length is defined as 33% of total dataset length, and then it will contain 4950 sign samples, as validation set will have 10050 samples. This splitting number is very usual, as it's a good practice to have a test set size lesser than the validation set size to avoid overfitting.\n",
    "\n",
    "The number of epochs running this training is defined above and it's defined equal 150 to provide enough information in how many epochs are needed to have a good classification rate without overtraining this neural network. Each epoch run will call the optimizer and cost functions, to acquire the networks weights and bias vectors, and after it will run the manual accuracy method that was told before to store and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdcc8a0a7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.4040389061\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    b = []\n",
    "    ac = []\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_matrix_scale, y_matrix, test_size=0.33)\n",
    "    for i in range(epochs):\n",
    "        _, a = sess.run([optimizer,cost],feed_dict={x:X_train,y:Y_train})\n",
    "        c = sess.run(accuracy,feed_dict={x:X_test,y:Y_test})\n",
    "        b.append(a)\n",
    "        ac.append(c)\n",
    "    \n",
    "    plt.plot(b)\n",
    "    plt.show()\n",
    "    \n",
    "    print(100*max(ac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "The MLP neural network results nearly 70% of accuracy, which represents that from 10050 samples used for validation, almost 7035 were right classified and 3015 were wrong. The resuls may change due the train_test_split method uses random set generation, so the test and validation set are probably different for each call. \n",
    "\n",
    "Thinking in a real world application in autonomous cars, it would not be a successful solution as it permits many recognition mistakes and promotes a bad decision, putting lives in risk. As a first attempt for this problem, it is a good result, but it also needs a better approach as desired for future works in this subject, like application of different neural network concepts as convolutional neural network for example, and optimization of parameters as layers and number of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
